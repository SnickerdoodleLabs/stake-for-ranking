\section{Recommender Systems}

\input{RecommenderActorsTikz}
Recommender systems are pervasive in all aspects of modern digital commerce, social media, and digital advertising networks \cite{resnick1997recommender} \cite{lops2011content} \cite{gomez2015netflix}. Google, Amazon, Meta, X.com, etc. all face the problem of how to suggest relevant content to their users. These systems face challenges in terms of scalability, transparency, and moderation \cite{wang2022trustworthy}. 

Serving the recommendations and training the associated models is a significant engineering challenge with a great deal of subjectivity present in determining what makes a recommendation relevant, particularly for content-based recommender systems. The mere act of a client-side application selecting a recommended content entity reveals information about the end-user to the broker of the recommendation which would allow the broker to potentially identify end users after multiple sessions and build user models without end user consent \cite{boutet2018collaborative}. The lack of economic repercussions for bad content authors and lack of incentive alignment between brokers, authors, and end users means recommender systems deployed in marketplace settings are highly susceptible to detrimental manipulation by all parties.

Stake for ranking specifically attempts to improve upon recommender systems where the content corpus and attribute space is potentially very large and the content authors are entities external to the broker of the recommendation engine (i.e the organization that operates the recommender system is not the same entity that authors content). It is these systems which are highly susceptible to sybil attack by malicious content authors who post poor quality, or even false information and are able to boost the ranking of their content by exploiting the ML/AI based algorithms that determine what content is served. This can be observed in the proliferation of fake/counterfeited product listings on Amazon, scam advertisements on Google, and bot reposts on Facebook and X.com. 

There is essentially no economic cost or historic traceability to the authors that create bad content; if they are removed from the system or deranked, they can simply create a new identity at no cost and try again. End consumers will have no means to independently verify the authenticity or history of the content author's identity \cite{lin2022shilling}. 

Additionally, well-meaning content authors, even those that are well known, are often censored, deranked, or demonetized with no warning or explanation and often with no verifiable indication that they have been deranked (colloquially known as "shadow banning"). Furthermore, the brokers of recommendation systems are not directly incentivized; to protect end users, they are instead directly incentivized to maximize engagement, which has a first-order effect on revenue generation. 
