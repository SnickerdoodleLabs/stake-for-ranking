\section{Recommender Systems}

\input{RecommenderActorsTikz}
Recommender systems are pervasive in all aspects of modern digital commerce, social media, and digital advertising networks \cite{resnick1997recommender} \cite{lops2011content} \cite{gomez2015netflix}. Google, Amazon, Meta, X.com, etc. all face the problem of how to suggest relevant content to their users. These systems face challenges in terms of scalability, transparency, and moderation \cite{wang2022trustworthy}. 

Serving the recommendations and training the associated models is a significant engineering challenge with a great deal of subjectivity present in determining what makes a recommendation relevant, particularly for content-based recommender systems. The mere act of a client-side application selecting a recommended content entity reveals information about the end-user to the broker of the recommendation or even third-party services which would significantly compromise end user privacy after multiple sessions without end user consent \cite{boutet2018collaborative}. The lack of economic repercussions for bad content authors and lack of incentive alignment between brokers, authors, and end users means recommender systems deployed in marketplace settings are highly susceptible to detrimental manipulation by all parties.

Stake for ranking specifically attempts to improve upon recommender systems where the content corpus and attribute space is potentially large and the content authors are entities external to the broker of the recommendation engine (i.e the organization that operates the recommender system is not the same entity that authors content). It is these systems which are highly susceptible to sybil attack by malicious content authors who post poor quality, or even false information and are able to boost the ranking of their content by exploiting ML/AI based algorithms that determine what content is served. This can be observed in the proliferation of fake/counterfeited product listings on Amazon, scam advertisements on Google, and bot reposts on Facebook and X.com. 

There is essentially no economic cost or historic traceability to the authors that create bad content; if they are removed from the system or deranked, they can simply create a new identity at no cost and try again. End consumers have no means to independently verify the authenticity or history of the content author's identity \cite{lin2022shilling}. 

Additionally, well-meaning content authors, even those that are well known, are often censored, deranked, or demonetized with no warning or explanation and often with no verifiable indication that they have been deranked (colloquially known as "shadow banning"). Furthermore, the brokers of recommendation systems are not directly incentivized to protect end users, they are instead directly incentivized to maximize engagement, which has a first-order effect on revenue generation. 

\subsection{Typical Recommender System Models}

There are two primary strategies by which modern recommender systems approach the task of calculating relevance of content to an end user: content-based filtering and collaborative filtering. While stake for ranking is most closely associated with content-based filtering, for completeness both are defined here. 

\subsubsection{Content-based Filtering}

Content-based filtering is a strategy where content is explicitly assigned keywords, features, or attributes in a database-like setting. These attributes are then compared against a user's profile state to determine relevance to that specific user. The user's profile is derived from their engagement with sites, shopping carts, and other pieces of content. 

Some of the advantages of content-based filtering include:
\begin{itemize}
    \item only the data from a user's personal profile is required to start producing recommendations. Hence, content-based filtering does not suffer from the "cold start" problem to the same degree that collaborative filtering systems do since they require many active users before recommendations can be optimized. 
    \item recommendations tend to be highly relevant to the user due to the direct match of a user's profile attributes with content attributes.
    \item recommendations are highly interpretable and transparent to the end user. 
    \item implementation simplicity. 
\end{itemize}

Some typical disadvantages of traditional content-based recommender systems include:
\begin{itemize}
    \item difficulty producing diverse or novel recommendations since only the user's own profile data and historical interactions are used for calculating relevance (unlike collaborative filtering where data from many user's are combined to produce recommendations). 
    \item difficulty scaling the recommender database since each content item must maintain a curated list of features or attributes which accurately and consistently represents the content.
\end{itemize}

\subsubsection{Collaborative Filtering}

Recommender systems which leverage collaborative filtering methods employ algorithms which combine many user profiles together into a single predictive model which is able to propose recommendations to a user. The winning proposal of the Netflix Prize \cite{gomez2015netflix} is a famous example of a collaborative filtering system based on a matrix factorization approach \cite{wu2007collaborative}. 

Collaborative filtering excels at:
\begin{itemize}
    \item recommending new relevant content outside of a user's historical interactions.
    \item high scalability for traditional implementations since there is no need to curate content features, only user profile data is required. 
\end{itemize}

However, collaborative filtering has drawbacks related to:
\begin{itemize}
    \item producing quality recommendations before there is a sufficient number of user profiles to train the recommender model (called the "cold start" problem). 
    \item producing interpretable or common-sense recommendations (since predictions take into account many user profiles which may have little or no overlap in taste). 
\end{itemize}